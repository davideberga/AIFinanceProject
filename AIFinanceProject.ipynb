{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv, set_option\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime\n",
    "import math\n",
    "from numpy.random import choice\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Import Model Packages for reinforcement learning\n",
    "#from keras import layers, models, optimizers\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "#from keras import backend as K\n",
    "from collections import namedtuple, deque\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class AIFinanceDataloader(Dataset):\n",
    "    def __init__(self, file_csv):\n",
    "        self.dataset = read_csv(file_csv, index_col=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        date = self.dataset.index[idx]\n",
    "        date = date.replace(':', '-').replace('T', '-')\n",
    "        year, month, day, hour, minute = date.split('-')[:-1]\n",
    "        \n",
    "        return {\n",
    "            'Year': int(year),\n",
    "            'Month': int(month),\n",
    "            'Day': int(day),\n",
    "            'Hour': int(hour),\n",
    "            'Minute': int(minute),\n",
    "            'Low': self.dataset.iloc[idx]['Low'],\n",
    "            'Volume': self.dataset.iloc[idx]['Volume'],\n",
    "            'Open': self.dataset.iloc[idx]['Open'],\n",
    "            'High': self.dataset.iloc[idx]['High'],\n",
    "            'Close': self.dataset.iloc[idx]['Close'],\n",
    "        }\n",
    "\n",
    "train_path = \"IVV_1m_training.csv\"\n",
    "validation_path = \"IVV_1m_validation.csv\"\n",
    "dataset = AIFinanceDataloader(file_csv = train_path)\n",
    "dataloader_train = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "dataset = AIFinanceDataloader(file_csv = validation_path)\n",
    "dataloader_val = DataLoader(dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diable the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AIFinanceDataloader' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# peek at data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m set_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.width\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AIFinanceDataloader' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "# peek at data\n",
    "set_option('display.width', 100)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe data\n",
    "#set_option('precision', 3)\n",
    "#dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values = False\n"
     ]
    }
   ],
   "source": [
    "#Checking for any null values and removing the null values'''\n",
    "print('Null Values =',dataset.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-03T14:30:00.000Z</th>\n",
       "      <td>142.10</td>\n",
       "      <td>133200</td>\n",
       "      <td>142.53</td>\n",
       "      <td>142.53</td>\n",
       "      <td>142.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-03T14:31:00.000Z</th>\n",
       "      <td>142.28</td>\n",
       "      <td>4400</td>\n",
       "      <td>142.28</td>\n",
       "      <td>142.45</td>\n",
       "      <td>142.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Low  Volume    Open    High   Close\n",
       "DateTime                                                        \n",
       "2007-01-03T14:30:00.000Z  142.10  133200  142.53  142.53  142.26\n",
       "2007-01-03T14:31:00.000Z  142.28    4400  142.28  142.45  142.45"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill the missing values with the last value available in the dataset. \n",
    "dataset=dataset.fillna(method='ffill')\n",
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=list(dataset[\"Close\"])\n",
    "X=[float(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "class AgentModel(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(AgentModel, self).__init__()\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.fc1 = nn.Linear(self.state_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 8)\n",
    "        self.fc4 = nn.Linear(8, self.action_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU(x)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.ReLU(x)\n",
    "        x = self.fc3(x)\n",
    "        x = nn.ReLU(x)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, window_size, is_eval=False, model_name=\"\", dataset_train=None, dataset_val=None):\n",
    "        super(Agent, self).__init__()\n",
    "        self.state_size = window_size\n",
    "        self.action_size = 3\n",
    "        self.memory = deque(maxlen=1000)\n",
    "        self.inventory = []\n",
    "        self.model_name = model_name\n",
    "        self.is_eval = is_eval\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.dataset_train = dataset_train\n",
    "        self.dataset_val = dataset_val\n",
    "        self.model = AgentModel(self.state_size, self.action_size)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\n",
    "    def act(self, state): \n",
    "        #If it is test and self.epsilon is still very high, once the epsilon become low, there are no random\n",
    "        #actions suggested.\n",
    "        if not self.is_eval and random.random() <= self.epsilon:\n",
    "            return random.randrange(self.action_size) \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            options = self.model(state)\n",
    "        \n",
    "        #set_trace()\n",
    "        #action is based on the action that has the highest value from the q-value function.\n",
    "        return np.argmax(options[0])\n",
    "\n",
    "    def expReplay(self, batch_size):\n",
    "        mini_batch = []\n",
    "        l = len(self.memory)\n",
    "        for i in range(l - batch_size + 1, l):\n",
    "            mini_batch.append(self.memory[i])\n",
    "        \n",
    "        # the memory during the training phase. \n",
    "        for state, action, reward, next_state, done in mini_batch:\n",
    "            target = reward # reward or Q at time t    \n",
    "            #update the Q table based on Q table equation\n",
    "            #set_trace()\n",
    "            if not done:\n",
    "                #set_trace()\n",
    "                #max of the array of the predicted. \n",
    "                self.model.eval()\n",
    "                with torch.no_grad():\n",
    "                    target = reward + self.gamma * np.amax(self.model(next_state)[0])     \n",
    "                \n",
    "            # Q-value of the state currently from the table   \n",
    "            self.model.eval()\n",
    "            with torch.no_grad(): \n",
    "                target_f = self.model(state)\n",
    "            # Update the output Q table for the given action in the table     \n",
    "            target_f[0][action] = target\n",
    "            #train and fit the model where state is X and target_f is Y, where the target is updated. \n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def training_loop(self, epochs = 1):\n",
    "        for _ in range(epochs):\n",
    "            for data in tqdm(self.dataset_train):\n",
    "                # Every data instance is an input + label pair\n",
    "                year, month, day, hour, minute, low, volume, open, high, close = data\n",
    "\n",
    "                # Zero your gradients for every batch!\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Make predictions for this batch\n",
    "                outputs = self.model(volume)\n",
    "\n",
    "                # Compute the loss and its gradients\n",
    "                loss = nn.MSELoss()\n",
    "                output = loss(outputs, close)\n",
    "                output.backward()\n",
    "\n",
    "                # Adjust learning weights\n",
    "                self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# prints formatted price\n",
    "def formatPrice(n):\n",
    "    return (\"-$\" if n < 0 else \"$\") + \"{0:.2f}\".format(abs(n))\n",
    "\n",
    "# # returns the vector containing stock data from a fixed file \n",
    "# def getStockData(key):\n",
    "#     vec = []\n",
    "#     lines = open(\"data/\" + key + \".csv\", \"r\").read().splitlines()\n",
    "\n",
    "#     for line in lines[1:]:\n",
    "#         vec.append(float(line.split(\",\")[4])) #Only Close column\n",
    "\n",
    "#     return vec\n",
    "\n",
    "# returns the sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "# returns an an n-day state representation ending at time t\n",
    "\n",
    "def getState(data, t, n):    \n",
    "    d = t - n + 1\n",
    "    block = data[d:t + 1] if d >= 0 else -d * [data[0]] + data[0:t + 1] # pad with t0\n",
    "    #block is which is the for [1283.27002, 1283.27002]\n",
    "    res = []\n",
    "    for i in range(n - 1):\n",
    "        res.append(sigmoid(block[i + 1] - block[i]))\n",
    "    return np.array([res])\n",
    "\n",
    "# Plots the behavior of the output\n",
    "def plot_behavior(data_input, states_buy, states_sell, profit):\n",
    "    fig = plt.figure(figsize = (15,5))\n",
    "    plt.plot(data_input, color='r', lw=2.)\n",
    "    plt.plot(data_input, '^', markersize=10, color='m', label = 'Buying signal', markevery = states_buy)\n",
    "    plt.plot(data_input, 'v', markersize=10, color='k', label = 'Selling signal', markevery = states_sell)\n",
    "    plt.title('Total gains: %f'%(profit))\n",
    "    plt.legend()\n",
    "    #plt.savefig('output/'+name+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running episode 0/10\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'getState' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(episode_count \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning episode \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(episode_count))\n\u001b[0;32m---> 15\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[43mgetState\u001b[49m(data, \u001b[38;5;241m0\u001b[39m, window_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m#set_trace()\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     total_profit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getState' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "window_size = 1\n",
    "agent = Agent(window_size, dataset_train=dataloader_train, dataset_val=dataloader_val)\n",
    "#In this step we feed the closing value of the stock price \n",
    "#data = X\n",
    "#l = len(data) - 1\n",
    "#\n",
    "batch_size = 16\n",
    "#An episode represents a complete pass over the data.\n",
    "episode_count = 10\n",
    "\n",
    "\n",
    "for e in range(episode_count + 1):\n",
    "    print(\"Running episode \" + str(e) + \"/\" + str(episode_count))\n",
    "    state = getState(data, 0, window_size + 1)\n",
    "    #set_trace()\n",
    "    total_profit = 0\n",
    "    agent.inventory = []\n",
    "    states_sell = []\n",
    "    states_buy = []\n",
    "    for t in range(l):\n",
    "        action = agent.act(state)    \n",
    "        # sit\n",
    "        next_state = getState(data, t + 1, window_size + 1)\n",
    "        reward = 0\n",
    "\n",
    "        if action == 1: # buy\n",
    "            agent.inventory.append(data[t])\n",
    "            states_buy.append(t)\n",
    "            #print(\"Buy: \" + formatPrice(data[t]))\n",
    "\n",
    "        elif action == 2 and len(agent.inventory) > 0: # sell\n",
    "            bought_price = agent.inventory.pop(0)      \n",
    "            reward = max(data[t] - bought_price, 0)\n",
    "            total_profit += data[t] - bought_price\n",
    "            states_sell.append(t)\n",
    "            #print(\"Sell: \" + formatPrice(data[t]) + \" | Profit: \" + formatPrice(data[t] - bought_price))\n",
    "\n",
    "        done = True if t == l - 1 else False\n",
    "        #appends the details of the state action etc in the memory, which is used further by the exeReply function\n",
    "        agent.memory.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            print(\"--------------------------------\")\n",
    "            print(\"Total Profit: \" + formatPrice(total_profit))\n",
    "            print(\"--------------------------------\")\n",
    "            #set_trace()\n",
    "            #pd.DataFrame(np.array(agent.memory)).to_csv(\"Agent\"+str(e)+\".csv\")\n",
    "            #Chart to show how the model performs with the stock goin up and down for each \n",
    "            plot_behavior(data,states_buy, states_sell, total_profit)\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.expReplay(batch_size)    \n",
    "            \n",
    "\n",
    "    if e % 2 == 0:\n",
    "        agent.model.save(\"model_ep\" + str(e))\n",
    "        torch.save(agent.model.state_dict(), \"model_ep\" + str(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
